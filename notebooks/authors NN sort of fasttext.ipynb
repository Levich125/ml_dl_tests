{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset https://www.kaggle.com/gdberrio/spooky-authors-csv\n",
    "Predict author of sentence (3 different authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import wordpunct_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 100  # sentences with length > 100 'words' will be cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/authors.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7900, 5635, 6044])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df['text']\n",
    "le = LabelEncoder().fit(df['author'])\n",
    "authors = le.transform(df['author'])\n",
    "np.bincount(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(authors)\n",
    "print(authors[:3])\n",
    "print(labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lowercase, punct padded with spaces\n",
    "texts_lower_punct = []\n",
    "for i in texts:\n",
    "    texts_lower_punct.append(' '.join([x for x in word_tokenize(i.lower())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it was our plan to remain where we were and intercept the liner dacia , mentioned in information from agents in new york .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_lower_punct[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15663 (3916, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts_lower_punct, labels, stratify=labels, test_size=0.2)\n",
    "print(len(X_train), y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\\t\\n')  # save the punctuation\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "wi = tokenizer.word_index\n",
    "wir = dict([(v, k) for k,v in wi.items()])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 'the',\n",
       " 'students',\n",
       " 'all',\n",
       " 'attended',\n",
       " 'the',\n",
       " 'hasty',\n",
       " 'funeral',\n",
       " 'on',\n",
       " 'the',\n",
       " 'th',\n",
       " ',',\n",
       " 'and',\n",
       " 'bought',\n",
       " 'an',\n",
       " 'impressive',\n",
       " 'wreath',\n",
       " ',',\n",
       " 'though',\n",
       " 'the',\n",
       " 'latter',\n",
       " 'was',\n",
       " 'quite',\n",
       " 'overshadowed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'tributes',\n",
       " 'sent',\n",
       " 'by',\n",
       " 'wealthy',\n",
       " 'arkham',\n",
       " 'citizens',\n",
       " 'and',\n",
       " 'by',\n",
       " 'the',\n",
       " 'municipality',\n",
       " 'itself',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wir.get(x, x) for x in X_train[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = max(wi.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 16)           372800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 372,851\n",
      "Trainable params: 372,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(max_features, 16, input_length = maxlen))\n",
    "# model.add(layers.LSTM(32, activation='relu', dropout=0.2))\n",
    "# model.add(layers.Flatten())\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Dense(3, activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb = [callbacks.EarlyStopping(monitor='val_loss', patience=5), \n",
    "      callbacks.ModelCheckpoint('../saved_models/authors_fast_text.hdf5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12530 samples, validate on 3133 samples\n",
      "Epoch 1/100\n",
      "12530/12530 [==============================] - 1s 111us/sample - loss: 1.0815 - acc: 0.4055 - val_loss: 1.0750 - val_acc: 0.3990\n",
      "Epoch 2/100\n",
      "12530/12530 [==============================] - 1s 81us/sample - loss: 1.0569 - acc: 0.4234 - val_loss: 1.0450 - val_acc: 0.4350\n",
      "Epoch 3/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 1.0138 - acc: 0.4868 - val_loss: 0.9964 - val_acc: 0.5037\n",
      "Epoch 4/100\n",
      "12530/12530 [==============================] - 1s 81us/sample - loss: 0.9518 - acc: 0.5782 - val_loss: 0.9363 - val_acc: 0.5768\n",
      "Epoch 5/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.8833 - acc: 0.6630 - val_loss: 0.8749 - val_acc: 0.7079\n",
      "Epoch 6/100\n",
      "12530/12530 [==============================] - 1s 82us/sample - loss: 0.8161 - acc: 0.7225 - val_loss: 0.8175 - val_acc: 0.7070\n",
      "Epoch 7/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.7550 - acc: 0.7558 - val_loss: 0.7673 - val_acc: 0.7408\n",
      "Epoch 8/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.6989 - acc: 0.7837 - val_loss: 0.7246 - val_acc: 0.7443\n",
      "Epoch 9/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.6525 - acc: 0.7993 - val_loss: 0.6876 - val_acc: 0.7660\n",
      "Epoch 10/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.6101 - acc: 0.8126 - val_loss: 0.6568 - val_acc: 0.7673\n",
      "Epoch 11/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.5749 - acc: 0.8251 - val_loss: 0.6286 - val_acc: 0.7887\n",
      "Epoch 12/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.5390 - acc: 0.8413 - val_loss: 0.6057 - val_acc: 0.7890\n",
      "Epoch 13/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.5089 - acc: 0.8516 - val_loss: 0.5833 - val_acc: 0.7964\n",
      "Epoch 14/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.4794 - acc: 0.8625 - val_loss: 0.5640 - val_acc: 0.8011\n",
      "Epoch 15/100\n",
      "12530/12530 [==============================] - 1s 82us/sample - loss: 0.4534 - acc: 0.8713 - val_loss: 0.5473 - val_acc: 0.8063\n",
      "Epoch 16/100\n",
      "12530/12530 [==============================] - 1s 81us/sample - loss: 0.4282 - acc: 0.8790 - val_loss: 0.5342 - val_acc: 0.8063\n",
      "Epoch 17/100\n",
      "12530/12530 [==============================] - 1s 82us/sample - loss: 0.4094 - acc: 0.8855 - val_loss: 0.5172 - val_acc: 0.8149\n",
      "Epoch 18/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.3871 - acc: 0.8933 - val_loss: 0.5051 - val_acc: 0.8168\n",
      "Epoch 19/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.3691 - acc: 0.9008 - val_loss: 0.4933 - val_acc: 0.8190\n",
      "Epoch 20/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.3497 - acc: 0.9057 - val_loss: 0.4827 - val_acc: 0.8200\n",
      "Epoch 21/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.3343 - acc: 0.9111 - val_loss: 0.4747 - val_acc: 0.8193\n",
      "Epoch 22/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.3187 - acc: 0.9148 - val_loss: 0.4660 - val_acc: 0.8254\n",
      "Epoch 23/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.3049 - acc: 0.9200 - val_loss: 0.4574 - val_acc: 0.8254\n",
      "Epoch 24/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.2893 - acc: 0.9238 - val_loss: 0.4503 - val_acc: 0.8276\n",
      "Epoch 25/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.2789 - acc: 0.9284 - val_loss: 0.4439 - val_acc: 0.8283\n",
      "Epoch 26/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.2653 - acc: 0.9320 - val_loss: 0.4379 - val_acc: 0.8292\n",
      "Epoch 27/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.2534 - acc: 0.9356 - val_loss: 0.4342 - val_acc: 0.8273\n",
      "Epoch 28/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.2417 - acc: 0.9374 - val_loss: 0.4298 - val_acc: 0.8321\n",
      "Epoch 29/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.2328 - acc: 0.9413 - val_loss: 0.4244 - val_acc: 0.8315\n",
      "Epoch 30/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.2238 - acc: 0.9425 - val_loss: 0.4217 - val_acc: 0.8289\n",
      "Epoch 31/100\n",
      "12530/12530 [==============================] - 1s 82us/sample - loss: 0.2136 - acc: 0.9457 - val_loss: 0.4223 - val_acc: 0.8283\n",
      "Epoch 32/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.2048 - acc: 0.9487 - val_loss: 0.4172 - val_acc: 0.8296\n",
      "Epoch 33/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.1982 - acc: 0.9504 - val_loss: 0.4134 - val_acc: 0.8312\n",
      "Epoch 34/100\n",
      "12530/12530 [==============================] - 1s 85us/sample - loss: 0.1896 - acc: 0.9532 - val_loss: 0.4113 - val_acc: 0.8356\n",
      "Epoch 35/100\n",
      "12530/12530 [==============================] - 1s 85us/sample - loss: 0.1802 - acc: 0.9555 - val_loss: 0.4101 - val_acc: 0.8331\n",
      "Epoch 36/100\n",
      "12530/12530 [==============================] - 1s 85us/sample - loss: 0.1754 - acc: 0.9559 - val_loss: 0.4085 - val_acc: 0.8379\n",
      "Epoch 37/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.1675 - acc: 0.9591 - val_loss: 0.4096 - val_acc: 0.8359\n",
      "Epoch 38/100\n",
      "12530/12530 [==============================] - 1s 85us/sample - loss: 0.1618 - acc: 0.9599 - val_loss: 0.4078 - val_acc: 0.8372\n",
      "Epoch 39/100\n",
      "12530/12530 [==============================] - 1s 84us/sample - loss: 0.1550 - acc: 0.9630 - val_loss: 0.4067 - val_acc: 0.8382\n",
      "Epoch 40/100\n",
      "12530/12530 [==============================] - 1s 81us/sample - loss: 0.1489 - acc: 0.9646 - val_loss: 0.4067 - val_acc: 0.8414\n",
      "Epoch 41/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.1436 - acc: 0.9667 - val_loss: 0.4069 - val_acc: 0.8395\n",
      "Epoch 42/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.1386 - acc: 0.9669 - val_loss: 0.4083 - val_acc: 0.8382\n",
      "Epoch 43/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.1312 - acc: 0.9693 - val_loss: 0.4089 - val_acc: 0.8395\n",
      "Epoch 44/100\n",
      "12530/12530 [==============================] - 1s 83us/sample - loss: 0.1280 - acc: 0.9702 - val_loss: 0.4094 - val_acc: 0.8417\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 100, batch_size = 64, validation_split=0.2, \n",
    "                   callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3814878599256562\n",
      "3916/3916 [==============================] - 0s 71us/sample - loss: 0.3815 - acc: 0.8463\n",
      "[0.38148786466991086, 0.8462717]\n"
     ]
    }
   ],
   "source": [
    "# dropout = 0.3\n",
    "model.load_weights('../saved_models/authors_fast_text.hdf5')\n",
    "X_test_check = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_check = pad_sequences(X_test_check, maxlen = maxlen)\n",
    "preds = model.predict_proba(X_test_check)\n",
    "print(log_loss(y_test, preds))\n",
    "print(model.evaluate(X_test_check, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Far better than 0.47 we got in authors MultinominalNB.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_main",
   "language": "python",
   "name": "ml_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
